\documentclass[sigconf=true, nonacm=false, review=true, anonymous = false,screen=true]{acmart}
\usepackage{soul}

% This is not the correct ref format but it shows the refs in the text more clearly
% Have to be removed before submitting
%\setcitestyle{authoryear}
%\setcitestyle{citesep={;}}
\copyrightyear{2023}
\acmYear{2023}
% \setcopyright{acmlicensed}
\setcopyright{none}
\acmConference[GECCO '23]{2023
Genetic and Evolutionary Computation Conference}{July 10--14,
2023}{Lisbon, Portugal}
\acmBooktitle{2023 Genetic and Evolutionary Computation Conference
 (GECCO '23), July 10--14, 2023, Lisbon, Portugal}
\acmPrice{15.00}
%%
%% Submission ID.
%%\acmSubmissionID{123-A56-BU3}
\newcommand{\dv}[1]{\textbf{\textcolor{blue}{Diederick: #1}}}
\newcommand{\ak}[1]{\textcolor{violet}{\textbf{Anna:} #1}}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Performance of Bayesian Optimizers on Strict Box Constrained Problems]{Performance of Bayesian Optimizers on Strict Box Constrained Problems in the SBOX-COST Benchmarking Suite} %\\example submission for a short paper in the SBOX-COST workshop

%%
%% authors
\author{Bas van Stein}
\affiliation{%
    \institution{LIACS, Leiden University}
    \streetaddress{Niels Bohrweg 1}
    \city{Leiden}
    \postcode{2333}
    \country{The Netherlands}}
\email{b.van.stein@liacs.leidenuniv.nl}
\orcid{0000-0002-0013-7969}

\author{Thomas B{\"a}ck}
\affiliation{%
      \institution{LIACS, Leiden University}
      \streetaddress{Niels Bohrweg 1}
      \city{Leiden}
      \postcode{2333}
      \country{The Netherlands}}
\email{t.h.w.baeck@liacs.leidenuniv.nl}
\orcid{0000-0001-6768-1478}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
\begin{abstract}
This paper evaluates several versions of Bayesian Optimization on the strict-box-constrained benchmarking suite (SBOX-COST). 
SBOX-COST is a variant of the well-known BBOB benchmark suite that enforces box-constraints by returning an invalid evaluation value for solutions violating any of the constraints on the bounds of decision variables. 
We compare X variants of Bayesian Optimization: 
TODO: add observations, rewrite slightly
\end{abstract}


%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10010070.10011796</concept_id>
       <concept_desc>Theory of computation~Theory of randomized search heuristics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10011254</concept_id>
       <concept_desc>Theory of computation~Algorithm design techniques</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Theory of randomized search heuristics}
\ccsdesc[500]{Theory of computation~Algorithm design techniques}


%%
%% Keywords.
\keywords{Bayesian Optimization, Box Constrained Optimization, Algorithm Performance}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Box-constraints impose limits on the domain of decision variables and are perhaps the most typical type of constraints that arise in black-box continuous optimization. In almost all real-world problems, the range of decision variables will be limited by physical, design, resource or policy bounds that are known a priori. As a result of these bounds, solutions outside those bounds, i.e., violating the box-constraints, are not only unacceptable, but they may not have a defined value of the objective function. Unfortunately, many optimization algorithms do not follow this assumption and, instead, allow the evaluation of solutions violating box-constraints. Moreover, benchmarking suites used for comparing algorithms, such as COCO/BBOB~\cite{hansen2020coco}, return a valid objective value for such solutions, which is used by the algorithms to steer their search.

Here, we consider a benchmark SBOX-COST that enforces box-constraints by returning the same invalid value ($\infty$) for any infeasible solution, thus the algorithm cannot use infeasible solutions to inform the search. We evaluate the effect that such strict-box-constraints have on the performance of some variants the Covariance Matrix Adaptation Evolution Strategy (CMA-ES).

The Covariance Matrix Adaptation Evolution Strategy (CMA-ES)~\cite{Hansen.1996} is a very popular heuristic optimisation algorithm for continuous optimisation problems~\cite{vermetten_gecco2022}. CMA-ES is considered state-of-the-art in evolutionary computation and has been adopted as one of the standard tools for continuous optimisation in many research labs. There are many flavours and variants of CMA-ES developed through the years and different implementations of sub-components such as the sampling strategy and the boundary correction method.

In recent works, the different modules and configurations of CMA-ES are explored and analysed based on their performance~\cite{de2021tuning}. In that research a modular CMA-ES framework is presented, representing a plethora of different CMA-ES configurations. In this paper, the modular CMA-ES framework is used to analyse the effect of introducing boundaries to standard BBOB problems, as done in the new SBOX-COST benchmark. 

This paper serves as an \textit{example} of a short paper for the ACM Workshop on Strict Box-Constrained Optimization\footnote{\url{https://sbox-cost.github.io/}} (SBOX-COST) within GECCO~2023.

\section{Methodology}
\subsection{SBOX-COST benchmarking suite}

For our benchmarking, we make use of the newly proposed Strict Box-Constraint Optimization Studies benchmark\footnote{\url{https://github.com/sbox-cost}} (SBOX-COST), which is a modification of the original BBOB suite~\cite{hansen2020coco}. The changes made are as follows: 
\begin{itemize}
    \item \textit{hard box-constraints}: points evaluated outside of the domain $[-5,5]^d$ are considered infeasible and evaluated to $\infty$;
    \item Location of the optima: SBOX-COST has optima across instances located uniformly within the full domain -- except for, as in BBOB, F4, F8, F9, F19, F20, F24 which have optima uniform in $[-4,4]^d$ and F5 - in some corners of $[-5,5]^d$.
\end{itemize} 

\subsection{Bayesian Optimization}

\begin{figure}[!tb]
 \centering
 \includegraphics[width=.95\linewidth,trim=1mm 5mm 13mm 9mm,clip]{Figures/ECDF_5D_CMAESS.pdf}
 \caption{Empirical Cumulative Distribution Function for all considered variants within modular CMA-ES, aggregated over the 24 functions of BBOB and SBOX-COST in 5D. Targets are 51 log-spaces values between $10^2$ and $10^{-8}$ ('bbob' default in IOHanalyzer).}\label{fig:res_ecdf}
\end{figure}
\section{Experimental setup}
We evaluate algorithms on the same 24 functions of both BBOB and SBOX-COST. The only difference between a function in both benchmark suites is the objective function value returned for solutions violating a box constraint.
We use an identical setup for BBOB and SBOX-COST: 15 instances per function, 1 run per instance, dimensionality $d\in\{5, 20, 40\}$, budget $10000\times d$.

Experiments reported in this study are carried out in the IOHex\-pe\-ri\-men\-ter environment~\cite{de2021iohexperimenter}, which implements both sets of benchmarking functions. 

\section{Results}
\begin{figure}[!tb]
 \centering
 \includegraphics[width=.95\linewidth,trim=1mm 5mm 13mm 9mm,clip]{Figures/ECDF_20D_CMAESS.pdf}
 \caption{Empirical Cumulative Distribution Function for all considered variants within modular CMA-ES, aggregated over the 24 functions of BBOB and SBOX-COST in 20D. Targets are 51 log-spaces values between $10^2$ and $10^{-8}$ ('bbob' default in IOHanalyzer).}\label{fig:res_ecdf2}
\end{figure}

\begin{figure*}
 \centering
 \includegraphics[width=.95\linewidth,trim=8mm 55mm 4mm 6mm,clip]{Figures/FCE_Mult-2023-03-30 (1).pdf}
 \includegraphics[width=.95\linewidth,trim=8mm 5mm 4mm 305mm,clip]{Figures/FCE_Mult-2023-03-30 (1).pdf}
 \caption{Mean function value over time for the CMA-ES methods with \texttt{centre} initialization, for 24 SBOX-COST functions of BBOB and SBOX-COST in 20D.}\label{fig:res_ert}
\end{figure*}

\input{FV_Table_Multi}


The data from the described experiments is visualized using IOHanalyzer~\cite{IOHanalyzer}. We start by aggregating the performance of each of the 8 settings across all 5-dimensional problems. This is done by making use of the Empirical Cumulative Distribution function, which aggregates the fraction of targets (we use the default of 51 logarithmically spaced targets $\{10^{-8}\dots10^{2}\}$) hit in each run on each function, as shown in Figure~\ref{fig:res_ecdf}. From this figure, we notice that the variants of CMA-ES without boundary correction run on the SBOX-suite perform slightly worse on aggregate than the other versions. 

In Figure~\ref{fig:res_ecdf2}, we show the ECDF curves on the 20-dimensional problems. Here, the poor performance of the CMA-ES with random initialization without boundary correction on SBOX is much more obvious. This is likely caused by the fact that in higher dimensions, a Gaussian distribution around a random point will be much more likely to generate points outside the domain, leading to many wasted function evaluations, and potentially a disrupted search process. While initializing the CMA-ES in the center of the domain alleviates this problem somewhat, it still performs worse than the versions which add a boundary handling mechanism. 

To get a more detailed view of the performance on individual functions, we plot the convergence trajectories (mean function value over time) in Figure~\ref{fig:res_ert}. To ease readability, we only show the CMA-ES variants which are initialized in the center of the domain. From this figure, we can see that for several functions, the performance differences between the algorithms run on SBOX and on BBOB are rather small. In particular, this is the case for the functions $\{4, 8, 9, 19, 20, 24\}$, where the instance generation procedure was not modified from the original BBOB suite. However, the differences on function $5$ clearly show the impact of the hard box-constraint, with the CMA-ES on BBOB easily solving the problem (achieved by moving outside the domain).

Finally, for a few selected functions, we show some detailed summary statistics in Table~\ref{tab:fce}, which confirms the observations from Figure~\ref{fig:res_ert}: for many problems, the CMA-ES can overcome the addition of hard box-constraints and changed function initialization, although there are some problems where the changes lead to a noticeable deterioration in performance.\footnote{Note that the discussion in this paper is purely for illustration purposes. In a submitted paper, this should be extended. }


\section{Conclusions}

In this paper we have benchmarked four variants of CMA-ES on SBOX-COST, which is a variant of the BBOB suite that enforces box-constraints. Our results clearly show that enforcing box-constraints has a negative effect on the performance of classical CMA-ES, specially with higher dimensionality. Although not handling box-constraints sometimes performs worse than the constraint handling method evaluated here (saturation), over all BBOB functions, handling box-constraints is clearly better than ignoring them when the box-constraints are strict.


\section*{Reproducibility}
To ensure the reproducibility of results presented in this paper, the complete code used for experiments and runs data in the IOH format have been uploaded to a Zenodo repository.\footnote{\url{https://doi.org/10.5281/zenodo.7649077}}

%%
%% The acknowledgments section is defined using the "acks" environment
%\begin{acks}
%\hl{anything?}
%\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
